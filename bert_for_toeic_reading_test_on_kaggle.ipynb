{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/code/tientd95/bert-model-for-anwsering-toeic-reading-test\n",
    "# !pip install -U pytorch-pretrained-bert;\n",
    "# !wget https://raw.githubusercontent.com/KHiraGit/khira_nl_lab/main/toeic_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TOEICBert():\n",
    "    \"\"\"\n",
    "    Model using pretrained Bert for answering toeic question, running for each example\n",
    "    Bertmodel: we can choose bert large cased/bert large uncased, etc\n",
    "    \n",
    "    Model return the answer for the question based on the highest probability\n",
    "    \"\"\"\n",
    "    def __init__(self, bertmodel):\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        self.bertmodel = bertmodel\n",
    "        # Initial tokenizer to tokenize the question later\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.bertmodel)\n",
    "        self.model = BertForMaskedLM.from_pretrained(self.bertmodel).to(self.device)\n",
    "         # We used pretrained BertForMaskedLM to fill in the blank, do not fine tuning so we set model to eval\n",
    "        self.model.eval()\n",
    "        \n",
    "    def get_score(self,question_tensors, segment_tensors, masked_index, candidate):\n",
    "        # Tokenize the answer candidate\n",
    "        candidate_tokens = self.tokenizer.tokenize(candidate)\n",
    "        # After tokenizing, we convert token to ids, (word to numerical)\n",
    "        candidate_ids = self.tokenizer.convert_tokens_to_ids(candidate_tokens)\n",
    "        predictions = self.model(question_tensors, segment_tensors)\n",
    "        predictions_candidates = predictions[0,masked_index, candidate_ids].mean()\n",
    "        return predictions_candidates.item()\n",
    "    \n",
    "    def predict(self,row):\n",
    "        # Tokenizing questions, convert '___' to '_' so that we can MASK it\n",
    "        question_tokens = self.tokenizer.tokenize(row['question'].replace('___', '_'))\n",
    "        masked_index = question_tokens.index('_')\n",
    "        # Assign [MASK] to blank that need to be completed\n",
    "        question_tokens[masked_index] = '[MASK]'\n",
    "        segment_ids = [0] * len(question_tokens)\n",
    "        segment_tensors = torch.tensor([segment_ids]).to(self.device)\n",
    "        question_ids = self.tokenizer.convert_tokens_to_ids(question_tokens)\n",
    "        question_tensors = torch.tensor([question_ids]).to(self.device)\n",
    "        candidates = [row['1'], row['2'], row['3'], row['4']]\n",
    "        # Return probabilities of answer choice [prob1, prob2, prob3, prob4]\n",
    "        predict_tensor = torch.tensor([self.get_score(question_tensors, segment_tensors,\n",
    "                                                masked_index, candidate) for candidate in candidates])\n",
    "        # Softmax the predict probability to return the index for maximum values\n",
    "        predict_idx = torch.argmax(predict_tensor).item()\n",
    "        return candidates[predict_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bertmodel  = 'bert-large-uncased'\n",
    "model = TOEICBert(Bertmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Answer_toeic(question):    \n",
    "    predict_anwser = model.predict(question)\n",
    "    anwser = question['anwser']\n",
    "    if predict_anwser == anwser:\n",
    "        print(f'The BertModel answer: {predict_anwser}')\n",
    "        print('This is right answer')\n",
    "    else:\n",
    "        print(f'The BertModel answer: {predict_anwser}')\n",
    "        print('This is wrong answer')\n",
    "        \n",
    "# now we have a TOEIC question on below:\n",
    "question = {'1': 'different',\n",
    " '2': 'differently',\n",
    " '3': 'difference',\n",
    " '4': 'differences',\n",
    " 'anwser': 'different',\n",
    " 'question': 'Matos Realty has developed two ___ methods of identifying undervalued properties.'}\n",
    "\n",
    "# Check the model\n",
    "Answer_toeic(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('toeic_test.json') as input_json:\n",
    "    data = json.load(input_json)\n",
    "\n",
    "# Data is a dictionary contain over 3000 toeic question\n",
    "# Let read the first question and familiar with format\n",
    "data['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data dict to list so that we can iterate them\n",
    "question_infors = []\n",
    "\n",
    "for key, value in data.items():\n",
    "    question_infors.append(value)\n",
    "\n",
    "question_infors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for question in question_infors:\n",
    "    anwser_predict = model.predict(question)\n",
    "    if anwser_predict == question['anwser']:\n",
    "        count+=1\n",
    "\n",
    "num_questions = len(question_infors)\n",
    "print(f'The model predict {round(count/num_questions,2) * 100} % of total {len(question_infors)} questions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3649c30ec85dac934afce0e542fb28ca10c17bdd51f836147bf5d35e42c51319"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
