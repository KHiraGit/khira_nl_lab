{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29e25006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対象テキストのダウンロード\n",
    "!wget https://nlp100.github.io/data/ai.ja.zip\n",
    "!unzip ai.ja.zip -d ai.ja\n",
    "!ls -l\n",
    "!ls -l ai.ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mecabのインストール\n",
    "!apt-get install mecab swig libmecab-dev mecab-ipadic-utf8 >/dev/null\n",
    "# mecab-pythonのインストール\n",
    "!pip -q install mecab-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a4b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crfpp のインストール\n",
    "import os\n",
    "filename_crfpp = 'crfpp.tar.gz'\n",
    "!wget \"https://drive.google.com/uc?export=download&id=0B4y35FiV1wh7QVR6VXJ5dWExSTQ\" \\\n",
    "    -O $filename_crfpp\n",
    "!tar zxvf $filename_crfpp\n",
    "%cd CRF++-0.58\n",
    "!./configure\n",
    "!make\n",
    "!make install\n",
    "%cd ..\n",
    "os.environ['LD_LIBRARY_PATH'] += ':/usr/local/lib' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cabocha のインストール\n",
    "FILE_ID = \"0B4y35FiV1wh7SDd1Q1dUQkZQaUU\"\n",
    "FILE_NAME = \"cabocha.tar.bz2\"\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$FILE_ID\" -O $FILE_NAME && rm -rf /tmp/cookies.txt\n",
    "!tar -xvf cabocha.tar.bz2\n",
    "%cd cabocha-0.69\n",
    "!./configure --with-mecab-config=`which mecab-config` --with-charset=UTF8\n",
    "!make\n",
    "!make check\n",
    "!make install\n",
    "%cd ..\n",
    "!cabocha --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed0ea5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8b33448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0 -1D 1/1 0.000000\n",
      "人工\t名詞,一般,*,*,*,*,人工,ジンコウ,ジンコー\n",
      "知能\t名詞,一般,*,*,*,*,知能,チノウ,チノー\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "EOS\n",
      "* 0 11D 1/3 -1.200307\n",
      "人工\t名詞,一般,*,*,*,*,人工,ジンコウ,ジンコー\n",
      "知能\t名詞,一般,*,*,*,*,知能,チノウ,チノー\n",
      "と\t助詞,格助詞,一般,*,*,*,と,ト,ト\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "* 1 2D 0/1 0.122505\n",
      "計算\t名詞,サ変接続,*,*,*,*,計算,ケイサン,ケイサン\n",
      "という\t助詞,格助詞,連語,*,*,*,という,トイウ,トユウ\n",
      "* 2 3D 0/1 0.823072\n",
      "概念\t名詞,一般,*,*,*,*,概念,ガイネン,ガイネン\n",
      "と\t助詞,並立助詞,*,*,*,*,と,ト,ト\n",
      "* 3 4D 0/1 1.598785\n",
      "コンピュータ\t名詞,一般,*,*,*,*,コンピュータ,コンピュータ,コンピュータ\n",
      "という\t助詞,格助詞,連語,*,*,*,という,トイウ,トユウ\n",
      "* 4 5D 0/1 2.110573\n",
      "道具\t名詞,一般,*,*,*,*,道具,ドウグ,ドーグ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "* 5 7D 0/1 1.300800\n",
      "用い\t動詞,自立,*,*,一段,連用形,用いる,モチイ,モチイ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "* 6 7D 0/1 2.172716\n",
      "知能\t名詞,一般,*,*,*,*,知能,チノウ,チノー\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "* 7 8D 1/1 1.285275\n",
      "研究\t名詞,サ変接続,*,*,*,*,研究,ケンキュウ,ケンキュー\n",
      "する\t動詞,自立,*,*,サ変・スル,基本形,する,スル,スル\n",
      "* 8 9D 2/3 1.295899\n",
      "計算\t名詞,サ変接続,*,*,*,*,計算,ケイサン,ケイサン\n",
      "機\t名詞,接尾,一般,*,*,*,機,キ,キ\n",
      "科学\t名詞,一般,*,*,*,*,科学,カガク,カガク\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "* 9 10D 1/2 2.023416\n",
      "一\t名詞,数,*,*,*,*,一,イチ,イチ\n",
      "分野\t名詞,一般,*,*,*,*,分野,ブンヤ,ブンヤ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "* 10 11D 0/0 -1.200307\n",
      "指す\t動詞,自立,*,*,五段・サ行,基本形,指す,サス,サス\n",
      "* 11 -1D 0/0 0.000000\n",
      "語\t名詞,一般,*,*,*,*,語,カタリ,カタリ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "EOS\n",
      "* 0 2D 0/1 0.345181\n",
      "言語\t名詞,一般,*,*,*,*,言語,ゲンゴ,ゲンゴ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "* 1 2D 0/1 2.217661\n",
      "理解\t名詞,サ変接続,*,*,*,*,理解,リカイ,リカイ\n",
      "や\t助詞,並立助詞,*,*,*,*,や,ヤ,ヤ\n",
      "* 2 3D 0/0 0.257647\n",
      "推論\t名詞,サ変接続,*,*,*,*,推論,スイロン,スイロン\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "* 3 4D 1/3 2.083214\n",
      "問題\t名詞,ナイ形容詞語幹,*,*,*,*,問題,モンダイ,モンダイ\n",
      "解決\t名詞,サ変接続,*,*,*,*,解決,カイケツ,カイケツ\n",
      "など\t助詞,副助詞,*,*,*,*,など,ナド,ナド\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "* 4 6D 1/2 0.693399\n",
      "知的\t名詞,一般,*,*,*,*,知的,チテキ,チテキ\n",
      "行動\t名詞,サ変接続,*,*,*,*,行動,コウドウ,コードー\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "* 5 6D 0/1 2.190897\n",
      "人間\t名詞,一般,*,*,*,*,人間,ニンゲン,ニンゲン\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "* 6 8D 0/1 1.505879\n",
      "代わっ\t動詞,自立,*,*,五段・ラ行,連用タ接続,代わる,カワッ,カワッ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "* 7 8D 0/1 2.525808\n",
      "コンピューター\t名詞,一般,*,*,*,*,コンピューター,コンピューター,コンピューター\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "* 8 9D 0/1 0.972434\n",
      "行わ\t動詞,自立,*,*,五段・ワ行促音便,未然形,行う,オコナワ,オコナワ\n",
      "せる\t動詞,接尾,*,*,一段,基本形,せる,セル,セル\n",
      "* 9 15D 2/2 0.093616\n",
      "技術\t名詞,一般,*,*,*,*,技術,ギジュツ,ギジュツ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "または\t接続詞,*,*,*,*,*,または,マタハ,マタワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "* 10 12D 1/2 1.216977\n",
      "計算\t名詞,サ変接続,*,*,*,*,計算,ケイサン,ケイサン\n",
      "機\t名詞,接尾,一般,*,*,*,機,キ,キ\n",
      "による\t助詞,格助詞,連語,*,*,*,による,ニヨル,ニヨル\n",
      "* 11 12D 0/1 1.098217\n",
      "知的\t名詞,形容動詞語幹,*,*,*,*,知的,チテキ,チテキ\n",
      "な\t助動詞,*,*,*,特殊・ダ,体言接続,だ,ナ,ナ\n",
      "* 12 14D 1/2 0.963408\n",
      "情報処理\t名詞,一般,*,*,*,*,情報処理,ジョウホウショリ,ジョーホーショリ\n",
      "システム\t名詞,一般,*,*,*,*,システム,システム,システム\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "* 13 14D 0/1 1.129035\n",
      "設計\t名詞,サ変接続,*,*,*,*,設計,セッケイ,セッケイ\n",
      "や\t助詞,並立助詞,*,*,*,*,や,ヤ,ヤ\n",
      "* 14 15D 0/1 0.778024\n",
      "実現\t名詞,サ変接続,*,*,*,*,実現,ジツゲン,ジツゲン\n",
      "に関する\t助詞,格助詞,連語,*,*,*,に関する,ニカンスル,ニカンスル\n",
      "* 15 16D 1/2 0.093616\n",
      "研究\t名詞,サ変接続,*,*,*,*,研究,ケンキュウ,ケンキュー\n",
      "分野\t名詞,一般,*,*,*,*,分野,ブンヤ,ブンヤ\n",
      "とも\t助詞,副助詞,*,*,*,*,とも,トモ,トモ\n",
      "* 16 -1D 0/1 0.000000\n",
      "さ\t動詞,自立,*,*,サ変・スル,未然レル接続,する,サ,サ\n",
      "れる\t動詞,接尾,*,*,一段,基本形,れる,レル,レル\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "EOS\n"
     ]
    }
   ],
   "source": [
    "file = os.path.join('ai.ja', 'ai.ja.txt') \n",
    "cleaned_file = os.path.join('ai.ja', 'ai.ja.txt.cleaned')  # 丸括弧でくくられた箇所を除去し、鍵括弧記号と空白を除去\n",
    "cleaned_parsed_file = os.path.join('ai.ja', 'ai.ja.txt.cleaned.parsed') # 処理後のテキストを句点で分割し、cabocha -f1 で係り受け解析を行った結果\n",
    "\n",
    "output = []\n",
    "with open(file, encoding='utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for text in lines:\n",
    "        sub_text = re.sub(r'（.*?）', '', text)\n",
    "        sub_text = re.sub(r'\\(.*?\\)', '', sub_text)\n",
    "        sub_text = re.sub(r'[「」『』【】]', '', sub_text)\n",
    "        sub_text = re.sub(r'\\s', '', sub_text)\n",
    "        for _sub_text in sub_text.split('。'):\n",
    "            if len(_sub_text) > 0:\n",
    "                output.append(_sub_text+'。\\n')\n",
    "\n",
    "with open(cleaned_file, 'w', encoding='utf-8') as f:\n",
    "    f.writelines(output)\n",
    "\n",
    "# cp = subprocess.run(['cabocha', '-f1', '-o', cleaned_parsed_file, cleaned_file])  # macbookpro の上で実行した\n",
    "\n",
    "i = 0\n",
    "with open(cleaned_parsed_file, encoding='utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for text in lines:\n",
    "        print(text)\n",
    "        if re.search(r'EOS', text):\n",
    "            i = i + 1\n",
    "        if i > 2:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de4635",
   "metadata": {},
   "source": [
    "* 第5章 係り受け解析 in 言語処理100本ノック\n",
    "* 40. 係り受け解析結果の読み込み（形態素）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95f87b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morph():\n",
    "    '''形態素を表すクラスMorph'''\n",
    "    def __init__(self, _i, _surface, _base, _pos, _pos1):\n",
    "        self.i = _i\n",
    "        self.surface = _surface\n",
    "        self.base = _base\n",
    "        self.pos = _pos\n",
    "        self.pos1 = _pos1\n",
    "        \n",
    "    def get(self):\n",
    "        return {'i': self.i, 'surface': self.surface, 'base': self.base, 'pos': self.pos, 'pos1': self.pos1}\n",
    "\n",
    "file = os.path.join('ai.ja', 'ai.ja.txt.cleaned.parsed')\n",
    "\n",
    "i = -1\n",
    "morphs = []\n",
    "\n",
    "with open(file, encoding='utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for text in lines:\n",
    "        if re.search(r'^\\*', text):\n",
    "            attr = text.split(' ')\n",
    "            i = int(attr[1])\n",
    "        elif not re.search(r'^EOS', text):\n",
    "            surface, tags = text.split('\\t')\n",
    "            tag = tags.split(',')\n",
    "            morphs.append(Morph(i, surface, tag[6], tag[0], tag[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ef227a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 {'i': 5, 'surface': 'いる', 'base': 'いる', 'pos': '動詞', 'pos1': '非自立'}\n",
      "101 {'i': 5, 'surface': '。', 'base': '。', 'pos': '記号', 'pos1': '句点'}\n",
      "102 {'i': 0, 'surface': '人間', 'base': '人間', 'pos': '名詞', 'pos1': '一般'}\n",
      "103 {'i': 0, 'surface': 'の', 'base': 'の', 'pos': '助詞', 'pos1': '連体化'}\n",
      "104 {'i': 1, 'surface': '知的', 'base': '知的', 'pos': '名詞', 'pos1': '一般'}\n",
      "105 {'i': 1, 'surface': '能力', 'base': '能力', 'pos': '名詞', 'pos1': '一般'}\n",
      "106 {'i': 1, 'surface': 'を', 'base': 'を', 'pos': '助詞', 'pos1': '格助詞'}\n",
      "107 {'i': 2, 'surface': 'コンピュータ', 'base': 'コンピュータ', 'pos': '名詞', 'pos1': '一般'}\n",
      "108 {'i': 2, 'surface': '上', 'base': '上', 'pos': '名詞', 'pos1': '接尾'}\n",
      "109 {'i': 2, 'surface': 'で', 'base': 'で', 'pos': '助詞', 'pos1': '格助詞'}\n",
      "110 {'i': 3, 'surface': '実現', 'base': '実現', 'pos': '名詞', 'pos1': 'サ変接続'}\n",
      "111 {'i': 3, 'surface': 'する', 'base': 'する', 'pos': '動詞', 'pos1': '自立'}\n",
      "112 {'i': 3, 'surface': '、', 'base': '、', 'pos': '記号', 'pos1': '読点'}\n",
      "113 {'i': 4, 'surface': '様々', 'base': '様々', 'pos': '名詞', 'pos1': '形容動詞語幹'}\n",
      "114 {'i': 4, 'surface': 'な', 'base': 'だ', 'pos': '助動詞', 'pos1': '*'}\n",
      "115 {'i': 5, 'surface': '技術', 'base': '技術', 'pos': '名詞', 'pos1': '一般'}\n",
      "116 {'i': 5, 'surface': '・', 'base': '・', 'pos': '記号', 'pos1': '一般'}\n",
      "117 {'i': 5, 'surface': 'ソフトウェア', 'base': 'ソフトウェア', 'pos': '名詞', 'pos1': '一般'}\n",
      "118 {'i': 5, 'surface': '・', 'base': '・', 'pos': '記号', 'pos1': '一般'}\n",
      "119 {'i': 5, 'surface': 'コンピュータ', 'base': 'コンピュータ', 'pos': '名詞', 'pos1': '一般'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,120):\n",
    "    print(i, morphs[i].get())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b8a0c",
   "metadata": {},
   "source": [
    "41. 係り受け解析結果の読み込み（文節・係り受け）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84f5ea1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Chunk():\n",
    "    '''文節を表すクラスChunk'''\n",
    "    def __init__(self, _i, _morphs, _dst):\n",
    "        self.i = _i\n",
    "        self.morphs = _morphs\n",
    "        self.dst = _dst\n",
    "        self.srcs = []\n",
    "\n",
    "_morphs = []\n",
    "_chunks = []\n",
    "sentences = []\n",
    "_dst = -1\n",
    "\n",
    "# file = os.path.join('ai.ja', 'ai.ja.txt.parsed')\n",
    "file = os.path.join('ai.ja', 'ai.ja.txt.cleaned.parsed')\n",
    "with open(file, encoding='utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for text in lines:\n",
    "        if re.search(r'^\\*', text):\n",
    "            if len(_morphs) > 0:\n",
    "                _chunks.append(Chunk(i, _morphs, _dst))\n",
    "                _morphs = []\n",
    "            i = int(text.split(' ')[1])\n",
    "            _dst = int(text.split(' ')[2].rstrip('D'))\n",
    "        elif not re.search(r'^EOS', text):\n",
    "            surface, tags = text.split('\\t')\n",
    "            if not re.search(r'[、。]', surface):\n",
    "                tag = tags.split(',')\n",
    "                _morphs.append(Morph(i, surface, tag[6], tag[0], tag[1]))\n",
    "        else:  # if text is 'EOS'\n",
    "            if len(_morphs) > 0:\n",
    "                _chunks.append(Chunk(i, _morphs, _dst))\n",
    "                for _chunk in _chunks:\n",
    "                    if _chunk.dst != -1:\n",
    "                        _chunks[_chunk.dst].srcs.append(_chunk.i)\n",
    "                \n",
    "                sentences.append(_chunks)\n",
    "                _morphs = []\n",
    "                _chunks = []\n",
    "                i = -1\n",
    "                _dst = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba48fa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['人工', '知能', 'と', 'は'] 11 []\n",
      "1 ['計算', 'という'] 2 []\n",
      "2 ['概念', 'と'] 3 [1]\n",
      "3 ['コンピュータ', 'という'] 4 [2]\n",
      "4 ['道具', 'を'] 5 [3]\n",
      "5 ['用い', 'て'] 7 [4]\n",
      "6 ['知能', 'を'] 7 []\n",
      "7 ['研究', 'する'] 8 [5, 6]\n",
      "8 ['計算', '機', '科学', 'の'] 9 [7]\n",
      "9 ['一', '分野', 'を'] 10 [8]\n",
      "10 ['指す'] 11 [9]\n",
      "11 ['語'] -1 [0, 10]\n"
     ]
    }
   ],
   "source": [
    "_chunks = sentences[1]\n",
    "for _chunk in _chunks:\n",
    "    _surface = []\n",
    "    for _morph in _chunk.morphs:\n",
    "        _surface.append(_morph.surface)\n",
    "    print(_chunk.i, _surface, _chunk.dst, _chunk.srcs)\n",
    "\n",
    "# for _chunks in sentences:\n",
    "#     for _chunk in _chunks:\n",
    "#         _surface = []\n",
    "#         for _morph in _chunk.morphs:\n",
    "#             _surface.append(_morph.surface)\n",
    "#         print(_chunk.i, _surface, _chunk.dst, _chunk.srcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622d8ed",
   "metadata": {},
   "source": [
    "42. 係り元と係り先の文節の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b642067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工知能とは\t語\n",
      "計算という\t概念と\n",
      "概念と\tコンピュータという\n",
      "コンピュータという\t道具を\n",
      "道具を\t用いて\n",
      "用いて\t研究する\n",
      "知能を\t研究する\n",
      "研究する\t計算機科学の\n",
      "計算機科学の\t一分野を\n",
      "一分野を\t指す\n",
      "指す\t語\n"
     ]
    }
   ],
   "source": [
    "_chunks = sentences[1]\n",
    "for _chunk in _chunks:\n",
    "    if _chunk.dst != -1:\n",
    "        _src_surface = ''\n",
    "        for _morph in _chunk.morphs:\n",
    "            _src_surface = _src_surface + _morph.surface\n",
    "        _dst_surface = ''\n",
    "        for _morph in _chunks[_chunk.dst].morphs:\n",
    "            _dst_surface = _dst_surface + _morph.surface\n",
    "        print(f'{_src_surface}\\t{_dst_surface}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a261e3",
   "metadata": {},
   "source": [
    "43. 名詞を含む文節が動詞を含む文節に係るものを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dbd01b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "これらを\t統合した\n",
      "知的システムを\t作る\n",
      "試みも\tなされている\n"
     ]
    }
   ],
   "source": [
    "_chunks = sentences[20]\n",
    "for _chunk in _chunks:\n",
    "    _noun_flag = False\n",
    "    _verb_flag = False\n",
    "    if _chunk.dst != -1:\n",
    "        _src_surface = ''\n",
    "        for _morph in _chunk.morphs:\n",
    "            _src_surface = _src_surface + _morph.surface\n",
    "            if _morph.pos == '名詞':\n",
    "                _noun_flag = True\n",
    "        _dst_surface = ''\n",
    "        for _morph in _chunks[_chunk.dst].morphs:\n",
    "            _dst_surface = _dst_surface + _morph.surface\n",
    "            if _morph.pos == '動詞':\n",
    "                _verb_flag = True\n",
    "        if _noun_flag and _verb_flag:\n",
    "            print(f'{_src_surface}\\t{_dst_surface}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165595d",
   "metadata": {},
   "source": [
    "44. 係り受け木の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d325d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工知能とは\t語\n",
      "計算という\t概念と\n",
      "概念と\tコンピュータという\n",
      "コンピュータという\t道具を\n",
      "道具を\t用いて\n",
      "用いて\t研究する\n",
      "知能を\t研究する\n",
      "研究する\t計算機科学の\n",
      "計算機科学の\t一分野を\n",
      "一分野を\t指す\n",
      "指す\t語\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Pages: 1 -->\n<svg width=\"283pt\" height=\"692pt\"\n viewBox=\"0.00 0.00 282.54 692.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 688)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-688 278.54,-688 278.54,4 -4,4\"/>\n<!-- 人工知能とは -->\n<g id=\"node1\" class=\"node\">\n<title>人工知能とは</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"68.89\" cy=\"-90\" rx=\"68.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"68.89\" y=\"-86.3\" font-family=\"MS Gothic\" font-size=\"14.00\">人工知能とは</text>\n</g>\n<!-- 語 -->\n<g id=\"node2\" class=\"node\">\n<title>語</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"126.89\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"126.89\" y=\"-14.3\" font-family=\"MS Gothic\" font-size=\"14.00\">語</text>\n</g>\n<!-- 人工知能とは&#45;&gt;語 -->\n<g id=\"edge1\" class=\"edge\">\n<title>人工知能とは&#45;&gt;語</title>\n<path fill=\"none\" stroke=\"black\" d=\"M82.93,-72.05C90.37,-63.08 99.62,-51.92 107.71,-42.15\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110.48,-44.29 114.17,-34.36 105.09,-39.82 110.48,-44.29\"/>\n</g>\n<!-- 計算という -->\n<g id=\"node3\" class=\"node\">\n<title>計算という</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"137.89\" cy=\"-666\" rx=\"59.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"137.89\" y=\"-662.3\" font-family=\"MS Gothic\" font-size=\"14.00\">計算という</text>\n</g>\n<!-- 概念と -->\n<g id=\"node4\" class=\"node\">\n<title>概念と</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"137.89\" cy=\"-594\" rx=\"39.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"137.89\" y=\"-590.3\" font-family=\"MS Gothic\" font-size=\"14.00\">概念と</text>\n</g>\n<!-- 計算という&#45;&gt;概念と -->\n<g id=\"edge2\" class=\"edge\">\n<title>計算という&#45;&gt;概念と</title>\n<path fill=\"none\" stroke=\"black\" d=\"M137.89,-647.7C137.89,-639.98 137.89,-630.71 137.89,-622.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"141.39,-622.1 137.89,-612.1 134.39,-622.1 141.39,-622.1\"/>\n</g>\n<!-- コンピュータという -->\n<g id=\"node5\" class=\"node\">\n<title>コンピュータという</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"137.89\" cy=\"-522\" rx=\"98.28\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"137.89\" y=\"-518.3\" font-family=\"MS Gothic\" font-size=\"14.00\">コンピュータという</text>\n</g>\n<!-- 概念と&#45;&gt;コンピュータという -->\n<g id=\"edge3\" class=\"edge\">\n<title>概念と&#45;&gt;コンピュータという</title>\n<path fill=\"none\" stroke=\"black\" d=\"M137.89,-575.7C137.89,-567.98 137.89,-558.71 137.89,-550.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"141.39,-550.1 137.89,-540.1 134.39,-550.1 141.39,-550.1\"/>\n</g>\n<!-- 道具を -->\n<g id=\"node6\" class=\"node\">\n<title>道具を</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"137.89\" cy=\"-450\" rx=\"39.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"137.89\" y=\"-446.3\" font-family=\"MS Gothic\" font-size=\"14.00\">道具を</text>\n</g>\n<!-- コンピュータという&#45;&gt;道具を -->\n<g id=\"edge4\" class=\"edge\">\n<title>コンピュータという&#45;&gt;道具を</title>\n<path fill=\"none\" stroke=\"black\" d=\"M137.89,-503.7C137.89,-495.98 137.89,-486.71 137.89,-478.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"141.39,-478.1 137.89,-468.1 134.39,-478.1 141.39,-478.1\"/>\n</g>\n<!-- 用いて -->\n<g id=\"node7\" class=\"node\">\n<title>用いて</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"137.89\" cy=\"-378\" rx=\"39.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"137.89\" y=\"-374.3\" font-family=\"MS Gothic\" font-size=\"14.00\">用いて</text>\n</g>\n<!-- 道具を&#45;&gt;用いて -->\n<g id=\"edge5\" class=\"edge\">\n<title>道具を&#45;&gt;用いて</title>\n<path fill=\"none\" stroke=\"black\" d=\"M137.89,-431.7C137.89,-423.98 137.89,-414.71 137.89,-406.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"141.39,-406.1 137.89,-396.1 134.39,-406.1 141.39,-406.1\"/>\n</g>\n<!-- 研究する -->\n<g id=\"node8\" class=\"node\">\n<title>研究する</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"185.89\" cy=\"-306\" rx=\"49.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"185.89\" y=\"-302.3\" font-family=\"MS Gothic\" font-size=\"14.00\">研究する</text>\n</g>\n<!-- 用いて&#45;&gt;研究する -->\n<g id=\"edge6\" class=\"edge\">\n<title>用いて&#45;&gt;研究する</title>\n<path fill=\"none\" stroke=\"black\" d=\"M149.27,-360.41C154.98,-352.08 162.03,-341.8 168.42,-332.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"171.5,-334.18 174.27,-323.96 165.72,-330.22 171.5,-334.18\"/>\n</g>\n<!-- 計算機科学の -->\n<g id=\"node10\" class=\"node\">\n<title>計算機科学の</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"185.89\" cy=\"-234\" rx=\"68.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"185.89\" y=\"-230.3\" font-family=\"MS Gothic\" font-size=\"14.00\">計算機科学の</text>\n</g>\n<!-- 研究する&#45;&gt;計算機科学の -->\n<g id=\"edge8\" class=\"edge\">\n<title>研究する&#45;&gt;計算機科学の</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.89,-287.7C185.89,-279.98 185.89,-270.71 185.89,-262.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"189.39,-262.1 185.89,-252.1 182.39,-262.1 189.39,-262.1\"/>\n</g>\n<!-- 知能を -->\n<g id=\"node9\" class=\"node\">\n<title>知能を</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"234.89\" cy=\"-378\" rx=\"39.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"234.89\" y=\"-374.3\" font-family=\"MS Gothic\" font-size=\"14.00\">知能を</text>\n</g>\n<!-- 知能を&#45;&gt;研究する -->\n<g id=\"edge7\" class=\"edge\">\n<title>知能を&#45;&gt;研究する</title>\n<path fill=\"none\" stroke=\"black\" d=\"M223.28,-360.41C217.39,-351.99 210.1,-341.58 203.53,-332.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"206.37,-330.14 197.76,-323.96 200.63,-334.16 206.37,-330.14\"/>\n</g>\n<!-- 一分野を -->\n<g id=\"node11\" class=\"node\">\n<title>一分野を</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"185.89\" cy=\"-162\" rx=\"49.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"185.89\" y=\"-158.3\" font-family=\"MS Gothic\" font-size=\"14.00\">一分野を</text>\n</g>\n<!-- 計算機科学の&#45;&gt;一分野を -->\n<g id=\"edge9\" class=\"edge\">\n<title>計算機科学の&#45;&gt;一分野を</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.89,-215.7C185.89,-207.98 185.89,-198.71 185.89,-190.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"189.39,-190.1 185.89,-180.1 182.39,-190.1 189.39,-190.1\"/>\n</g>\n<!-- 指す -->\n<g id=\"node12\" class=\"node\">\n<title>指す</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"185.89\" cy=\"-90\" rx=\"29.8\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"185.89\" y=\"-86.3\" font-family=\"MS Gothic\" font-size=\"14.00\">指す</text>\n</g>\n<!-- 一分野を&#45;&gt;指す -->\n<g id=\"edge10\" class=\"edge\">\n<title>一分野を&#45;&gt;指す</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.89,-143.7C185.89,-135.98 185.89,-126.71 185.89,-118.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"189.39,-118.1 185.89,-108.1 182.39,-118.1 189.39,-118.1\"/>\n</g>\n<!-- 指す&#45;&gt;語 -->\n<g id=\"edge11\" class=\"edge\">\n<title>指す&#45;&gt;語</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.8,-73.46C164.98,-64.18 154.9,-52.23 146.18,-41.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"148.67,-39.4 139.55,-34.01 143.31,-43.91 148.67,-39.4\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x27de0e31b50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "# グラフの作成、フォント設定\n",
    "dot = Digraph(format='png')\n",
    "dot.attr('node', fontname=\"MS Gothic\")\n",
    "\n",
    "# 42.係り元と係り先の文節の表示 にグラフ作成を追加\n",
    "_chunks = sentences[1]\n",
    "for _chunk in _chunks:\n",
    "    if _chunk.dst != -1:\n",
    "        _src_surface = ''\n",
    "        for _morph in _chunk.morphs:\n",
    "            _src_surface = _src_surface + _morph.surface\n",
    "        _dst_surface = ''\n",
    "        for _morph in _chunks[_chunk.dst].morphs:\n",
    "            _dst_surface = _dst_surface + _morph.surface\n",
    "        print(f'{_src_surface}\\t{_dst_surface}')\n",
    "        \n",
    "        dot.node(_src_surface)\n",
    "        dot.node(_dst_surface)\n",
    "        dot.edge(_src_surface, _dst_surface)\n",
    "        \n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ee415",
   "metadata": {},
   "source": [
    "45. 動詞の格パターンの抽出\n",
    "* 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1789830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 する\tを \t(55)\n",
      "2 する\tと \t(23)\n",
      "3 する\tが \t(21)\n",
      "4 する\tに \t(14)\n",
      "5 れる\tと \t(13)\n",
      "6 する\tは を \t(13)\n",
      "7 よる\tに \t(12)\n",
      "8 する\tに を \t(10)\n",
      "9 する\tで を \t(9)\n",
      "10 する\tが に \t(9)\n"
     ]
    }
   ],
   "source": [
    "_cases = {}\n",
    "for _chunks in sentences:\n",
    "    for _chunk in _chunks:\n",
    "        for _morph in _chunk.morphs:\n",
    "            if _morph.pos == '動詞':\n",
    "                _particles = []\n",
    "                for _src in _chunk.srcs:\n",
    "                    if _chunks[_src].morphs[-1].pos == '助詞':\n",
    "                        if _chunks[_src].morphs[-1].base not in _particles:\n",
    "                            _particles.append(_chunks[_src].morphs[-1].base)\n",
    "                if len(_particles) > 0:\n",
    "                    _particles.sort()\n",
    "                    _particle_list = ' '.join(_particles)\n",
    "                    _key = f'{_morph.base}:{_particle_list}'\n",
    "                    if _key not in _cases:\n",
    "                        _cases[_key] = 0\n",
    "                    _cases[_key] = _cases[_key] + 1\n",
    "\n",
    "i = 1\n",
    "for _key, _value in sorted(_cases.items(), key=lambda x:x[1], reverse=True):\n",
    "    _key = re.sub(r':', '\\t', _key)\n",
    "    print(i, _key, f'\\t({_value})')\n",
    "    i = i + 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b197b8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行う\tを \t(8)\n",
      "行う\tは を \t(2)\n",
      "行う\tて に \t(1)\n",
      "行う\tに を \t(1)\n",
      "行う\tが に は \t(1)\n",
      "行う\tに \t(1)\n",
      "行う\tに により を \t(1)\n",
      "行う\tて に を \t(1)\n",
      "行う\tは \t(1)\n",
      "行う\tで に を \t(1)\n",
      "行う\tで を \t(1)\n",
      "行う\tに まで を \t(1)\n",
      "行う\tが は \t(1)\n",
      "行う\tが で は \t(1)\n",
      "行う\tは を をめぐって \t(1)\n",
      "行う\tで は まで を \t(1)\n"
     ]
    }
   ],
   "source": [
    "for _key, _value in sorted(_cases.items(), key=lambda x:x[1], reverse=True):\n",
    "    if re.search(r'^行う', _key):\n",
    "        _key = re.sub(r':', '\\t', _key)\n",
    "        print(_key, f'\\t({_value})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "257cbaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "なる\tが と \t(4)\n",
      "なる\tに は \t(4)\n",
      "なる\tに \t(2)\n",
      "なる\tと \t(2)\n",
      "なる\tは も \t(2)\n",
      "なる\tと など \t(1)\n",
      "なる\tに によって は \t(1)\n",
      "なる\tが \t(1)\n",
      "なる\tから で と \t(1)\n",
      "なる\tが は \t(1)\n",
      "なる\tが に \t(1)\n",
      "なる\tが に は \t(1)\n",
      "なる\tは \t(1)\n",
      "なる\tて は \t(1)\n",
      "なる\tが で に \t(1)\n",
      "なる\tから が で も \t(1)\n",
      "なる\tで に は \t(1)\n",
      "なる\tから が て と は ば \t(1)\n",
      "なる\tとして に は \t(1)\n",
      "なる\tが で と に は \t(1)\n",
      "なる\tが にとって は \t(1)\n",
      "なる\tと を \t(1)\n",
      "なる\tは を \t(1)\n",
      "なる\tで は \t(1)\n"
     ]
    }
   ],
   "source": [
    "for _key, _value in sorted(_cases.items(), key=lambda x:x[1], reverse=True):\n",
    "    if re.search(r'^なる', _key):\n",
    "        _key = re.sub(r':', '\\t', _key)\n",
    "        print(_key, f'\\t({_value})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99cd2dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "与える\tが に \t(2)\n",
      "与える\tに は を \t(1)\n"
     ]
    }
   ],
   "source": [
    "for _key, _value in sorted(_cases.items(), key=lambda x:x[1], reverse=True):\n",
    "    if re.search(r'^与える', _key):\n",
    "        _key = re.sub(r':', '\\t', _key)\n",
    "        print(_key, f'\\t({_value})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69208e3b",
   "metadata": {},
   "source": [
    "46. 動詞の格フレーム情報の抽出\n",
    "* 45のプログラムを改変し，述語と格パターンに続けて項（述語に係っている文節そのもの）をタブ区切り形式で出力\n",
    "  * 項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）\n",
    "  * 述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる\n",
    "\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」\n",
    "```\n",
    "    作り出す\tで は を\t会議で ジョンマッカーシーは 用語を\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb4a88f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用いる\tを\t道具を\n",
      "する\tて を\t用いて 知能を\n",
      "指す\tを\t一分野を\n",
      "代わる\tを に\t知的行動を 人間に\n",
      "行う\tて に\t代わって コンピューターに\n",
      "する\tとも\t研究分野とも\n",
      "述べる\tで は に\t解説で 佐藤理史は 次のように\n",
      "する\tを で\t知的能力を コンピュータ上で\n",
      "する\tを\t推論・判断を\n",
      "する\tを\t画像データを\n",
      "する\tて を\t解析して パターンを\n",
      "ある\tは が\t応用例は 画像認識等が\n",
      "する\tに で により\t1956年に ダートマス会議で ジョン・マッカーシーにより\n",
      "用いる\tを\t記号処理を\n",
      "する\tを と\t記述を 主体と\n",
      "使う\tは でも\t現在では 意味あいでも\n",
      "呼ぶ\tも\t思考ルーチンも\n",
      "ある\tも\tことも\n",
      "よる\tに\tプログラミング言語に\n",
      "する\tを\tカウンセラーを\n",
      "出す\tが に\tプログラムが 引き合いに\n",
      "する\tに を\t計算機に 役割を\n",
      "呼ぶ\tと\tエキスパートシステムと\n",
      "持つ\tが に\t人間が 暗黙に\n",
      "なる\tが と\t記述が 問題と\n",
      "する\tが は\t出されるが 実現は 利用が\n",
      "知る\tは も\tアプローチとしては アプローチも\n",
      "ある\tが は に\t知られているが 差は 記号的明示性に\n",
      "集める\tが を\tサポートベクターマシンが 注目を\n",
      "行う\tを に\t経験を 元に 学習を\n",
      "ある\tも\t手法も\n",
      "する\tを に\t知性を 機械的に\n",
      "超える\tを\t流行を\n",
      "する\tて に\t超えて 社会に\n",
      "行く\tにより て\t登場により 浸透して\n",
      "する\tにかけて を\t2017年にかけて ディープラーニングを\n",
      "破る\tも\tプレイヤーも\n",
      "する\tは が として に\t麻雀では MicrosoftSuphxが AIとして 十段に\n",
      "なる\tなど と\t到達するなど 最先端技術と\n",
      "呼ぶ\tは と\t人工知能は 機械学習と\n",
      "ある\tが\tものが\n",
      "繰り返す\tを\t学習を\n",
      "する\tは を と\t計算知能は ことを 基本と\n",
      "基づく\tに\t経験に\n",
      "する\tと\tソフトコンピューティングと\n",
      "ある\tは が\t手法としては ものが\n",
      "する\tを\tこれらを\n",
      "作る\tを\t知的システムを\n",
      "なす\tも\t試みも\n",
      "する\tは を に を通して\tACT-Rでは 推論ルールを 統計的学習を 元に 生成規則を通して\n",
      "上回る\tで を\t領域で 人工知能を\n",
      "出す\tを\t精度を\n",
      "行う\tは が に\t第3次人工知能ブームでは 研究が 盛んに\n",
      "でる\tが\t派生が\n",
      "する\tは て で\t最近では でて 各分野で\n",
      "だす\tが で を\tディープラーニングが 分野で 成果を\n",
      "加える\tに\tことに\n",
      "見せる\tは て において を\tGANは 加えて 生成技術において 進化を\n",
      "広がる\tに が\t背景に 応用分野が\n",
      "行う\tを\tコンテンツ生成を\n",
      "始まる\tも\t応用も\n",
      "する\tは と\t森正弥は 始まっていると\n",
      "なる\tが と\t試みられてきているが 解決が 壁と\n",
      "する\tは が と\tルネ・デカルトは 身体が 機械であると\n",
      "する\tは を\tブレーズ・パスカルは 機械式計算機を\n",
      "行う\tは を\tエイダ・ラブレスは 開発を\n",
      "する\tを\t数学原理を\n",
      "もたらす\tは に を\tアルフレッド・ノース・ホワイトヘッドは 形式論理に 革命を\n",
      "する\tに\t神経活動に\n",
      "題する\tと\t論理計算と\n",
      "する\tを に\t論文を 1943年に\n",
      "築く\tは を\tウォルター・ピッツは 基礎を\n",
      "なる\tに\t1950年代に\n",
      "出る\tと に関して が\tなると AIに関して 成果が\n",
      "作り出す\tは で を\tジョン・マッカーシーは 会議で 用語を\n",
      "する\tを\tプログラミング言語を\n",
      "する\tを\tテストを\n",
      "する\tとして は を\t方法として アラン・チューリングは チューリングテストを\n",
      "する\tを\tジョセフ・ワイゼンバウムはを\n",
      "行う\tを\t来談者中心療法を\n",
      "行う\tに\t1956年に\n",
      "する\tにおいて として\t提案書において 用語として\n",
      "する\tとして\t分野として\n",
      "示す\tに は で を\t間に ジョエル・モーゼスは プログラム中で パワーを\n",
      "する\tを\tパーセプトロンを\n",
      "示す\tは て を\tシーモア・パパートは 出版して 限界を\n",
      "する\tは を\tアラン・カルメラウアーは プログラミング言語を\n",
      "する\tを\tルールベースシステムを\n",
      "示す\tは を\tテッド・ショートリッフェは パワーを\n",
      "呼ぶ\tと\tエキスパートシステムと\n",
      "ある\tは も\tこれは ことも\n",
      "する\tを に\tコースを 自律的に\n",
      "する\tを\t乗り物を\n",
      "使う\tに は によって\t1980年代に ニューラルネットワークは バックプロパゲーションアルゴリズムによって\n",
      "する\tに が は を\t時代に ロドニー・ブルックスが 知能には 学説を\n",
      "上げる\tは で が を\t1990年代は 分野で アプリケーションが 成果を\n",
      "する\tに\t世界チャンピオンに\n",
      "する\tに は を\t1992年に IBMは バックギャモン専用コンピュータ・TDギャモンを\n",
      "打つ\tに を\t5月に ガルリ・カスパロフを\n",
      "敗れる\tは で に が\tチェス専用コンピュータ・ディープ・ブルーは 8月には オセロで オセロ専用コンピュータ・ロジステロに 村上健が\n",
      "する\tにおいて を\t湾岸戦争において ユニットを\n",
      "使う\tのに を\tスケジューリングするのに AIを\n",
      "省く\tによって\tこれによって\n",
      "上回る\tが を\tコストが 投資全額を\n",
      "する\tは を\t国防高等研究計画局は ことを\n",
      "する\tが に\t甘利俊一らが 精力的に\n",
      "する\tは も\t日本では 成果も\n",
      "する\tが\t発生したが ブラックボックス性が\n",
      "する\tは が\t1998年には XMLが\n",
      "適す\tに\tアプリケーション別に\n",
      "する\tから に対して を\tここから 非構造化データに対して 意味付けを\n",
      "行う\tを\t処理を\n",
      "する\tが\t提唱されたが 試みが\n",
      "行う\tにより に を\tティム・バーナーズ＝リーにより Webに 知的処理を\n",
      "する\tに が\t同年に セマンティック・ウェブが\n",
      "する\tに を\tデータに 意味を\n",
      "行う\tて に を\t付加して コンピュータに 知的処理を\n",
      "する\tを に\t方法を 国際的に\n",
      "する\tを\tオントロジーを\n",
      "含む\tは も\t規格には OWLも\n",
      "分かる\tから が\tことから ことが\n",
      "する\tに が\t前半に 規格化が\n",
      "見合う\tに\t開発工数に\n",
      "見出せる\tが\tメリットが\n",
      "する\tが は から も\t完了しているが Web開発者にとっては ことから 現在も 普及は\n",
      "する\tは に が\t日本においては 後に ニューロファジィが\n",
      "進む\tが\t研究が\n",
      "する\tにつれて に\t進むにつれて フレーム問題に\n",
      "する\tを\t在り方を\n",
      "至る\tに\tAIに\n",
      "する\tは\tブームは\n",
      "入る\tに\t1980年代に\n",
      "基づく\tに\t知識工学に\n",
      "する\tが\tエキスパートシステムが\n",
      "する\tを と\tエキスパートシステムを 専門と\n",
      "立ち上がる\tて に も と\t入って 中心に AIベンチャーも 次々と\n",
      "生まれる\tから\t流行から\n",
      "挙げる\tとして が\tプロジェクトとして 第五世代コンピュータが\n",
      "費やす\tとして を\t国家プロジェクトとして 570億円を\n",
      "進める\tて を\t費やして 研究を\n",
      "異なる\tで が\t専門家間で 解釈が\n",
      "行える\tが\tルール化が\n",
      "ある\tは も\t場合には 問題も\n",
      "至る\tまで は も\t1992年まで 日本は 進めるも 実現には\n",
      "する\tを で\t命令を 機構で\n",
      "する\tて に\t解釈して 高速に\n",
      "見つかる\tが で\tProlog専用機であるが 意味で 応用先が\n",
      "用いる\tにかけて から として\t中頃にかけて 従来から 手法として\n",
      "する\tを\t問題を\n",
      "する\tが に\t知的制御が 盛んに\n",
      "用いる\tを\tルールを\n",
      "する\tを\t特徴を\n",
      "する\tて\t学習して\n",
      "する\tを\t2つを\n",
      "迎える\tが に を\t手法が 中心に ブームを\n",
      "合わせる\tに\t高級路線に\n",
      "増やす\tて も を に\t合わせて 白物家電製品でも 種類を 大幅に\n",
      "する\tに を\t元に 運転を\n",
      "する\tが\tモデルが\n",
      "する\tに が を\t2018年までに 日本が 特許を\n",
      "なる\tから で と\t事から 日本で ブームと\n",
      "分かる\tは が\tファジィについては ことが\n",
      "する\tより\t当時より\n",
      "用いる\tは が\t白物家電では 制御技術が\n",
      "なる\tに\tものに\n",
      "する\tが は\t用いられているが 利用者には\n",
      "なる\tが に\tニューロファジィが ブームに\n",
      "行う\tは\t産業応用は\n",
      "巻き込む\tも\t一般人も\n",
      "する\tが で\tニューラルネットワークが 巻き込んで\n",
      "言える\tも\t前史とも\n",
      "言える\tと\t社会現象と\n",
      "持つ\tが から\t松下電器が 1985年頃から 人間が\n",
      "活かす\tを に\t曖昧さを 制御に\n",
      "する\tを\t研究を\n",
      "漕ぎ着ける\tに\t1日に 発売に\n",
      "する\tも で\t従来よりも センサーで\n",
      "基づく\tに\tデータに\n",
      "する\tて に を\t基づいて 柔軟に 運転を\n",
      "する\tという が も\tファジィ制御という 導入が 高級路線にも\n",
      "関わる\tも\t制御技術であるにも\n",
      "集める\tから は を\tことから ファジィは 注目を\n",
      "選ぶ\tで が\t金賞で ファジィが\n",
      "する\tを\tチューニングを\n",
      "する\tを\tニューロファジィ制御を\n",
      "する\tを\t限界を\n",
      "する\tて で\t突破して 学会で\n",
      "する\tも\t応用にも\n",
      "巻き起こす\tに は て を\tその後に 松下電器は 成功して ブームを\n",
      "受ける\tを\t成功を\n",
      "用いる\tて も を\t受けて 他社も 知的制御を\n",
      "する\tを\t製品を\n",
      "売る\tの\t白物家電の\n",
      "用いる\tは として が に\t中頃までは 売り文句として 名称が 大々的に\n",
      "する\tは が\t製品名では 分類としては 運転モードでは 名称が\n",
      "する\tを で に\t対象を 数式で 客観的に\n",
      "ある\tが\t必要が\n",
      "する\tと\t現代制御等と\n",
      "なる\tが と\t特徴が 利用可能と\n",
      "抑える\tを\t開発工数を\n",
      "できる\tながら を\t抑えながら 柔軟性を\n",
      "ある\tは て が\t手法は 比較して ニューロファジィは 利点が\n",
      "関わる\tも\t努力にも\n",
      "する\tから を\t少なさから 制御を\n",
      "迎える\tで を\t程度で 限界を\n",
      "与える\tが に\tデータが 潤沢に\n",
      "ある\tも は が\t与えられたとしても 向上には 限界が\n",
      "進む\tから は として\t能力限界から 改善は 遅々として\n",
      "無くなる\tは\t進展は\n",
      "する\tを\t知的制御を\n",
      "なる\tは が に\t末には 白物家電が 大多数に\n",
      "去る\tは\tブームは\n",
      "する\tは\tブーム後は 一般には\n",
      "使う\tも\t社会インフラにも\n",
      "する\tが は として に\t意識されなくなったが 現在では 技術として 十分に 安定性が\n",
      "する\tが\t人間が\n",
      "する\tを\tオントロジーを\n",
      "する\tは に\t2003年頃には 分野に\n",
      "する\tが で を\t人工知能が 点で 人間を\n",
      "担う\tを\t進歩を\n",
      "する\tを\t世界を\n",
      "訪れる\tが も\t技術的特異点が 2045年にも\n",
      "する\tと\t訪れると\n",
      "する\tは で を\tレイ・カーツワイルは 著作で 説を\n",
      "する\tに により が\t2006年に 研究チームにより 深層化手法が\n",
      "入る\tに\t2010年代に\n",
      "扱う\tを\tデータを\n",
      "する\tが\t環境が\n",
      "する\tが\t研究が\n",
      "する\tに で が\t2010年に 英国エコノミスト誌で 用語が\n",
      "する\tに が で\t同年に ワトソンが 練習戦で 人間に\n",
      "なる\tと\tニュースと\n",
      "果たす\tに で が を\t2012年に 画像処理コンテストで チームが 精度改善を\n",
      "する\tで\t上で\n",
      "始まる\tが\t第三次AIブームが\n",
      "する\tが\t研究チームが\n",
      "挑む\tは で に\t2013年には 東ロボくんで 模擬試験に\n",
      "する\tと\t挑んだと\n",
      "使う\tを\t専用プログラムを\n",
      "臨む\tに が\t実際に 受験生が\n",
      "する\tを\t問題を\n",
      "先立つ\tにより に\t齊藤元章により 特異点に\n",
      "近づく\tにより が\t進歩により 生産コストが\n",
      "する\tは も\t2014年には 概念も\n",
      "向ける\tに\t実現に\n",
      "続ける\tが て を\tジェフ・ホーキンスが 向けて 研究を\n",
      "する\tが で を\t続けているが 中で 理論を\n",
      "向ける\tに\t実用化に\n",
      "進む\tにおいて に が\t世界各国において 軍事・民間共に 研究開発が\n",
      "する\tが\t進んでいるが 開発が\n",
      "留まる\tものの は に\tものの 2010年代には 自動化は ものに\n",
      "する\tが\tロドニー・ブルックスが\n",
      "する\tは が\tロボット向けとしては 理論が\n",
      "思う\tの\t従来型の\n",
      "する\tが\t知が\n",
      "用いる\tを\t神経ネットワークのみを\n",
      "する\tて から\t用いて 環境から\n",
      "用いる\tは を\tこれは 行動型システムを\n",
      "基づく\tに\tこれに\n",
      "呼ぶ\tと\tゲンギスと\n",
      "持つ\tを\t脳を\n",
      "関わる\tも\t持たないにも\n",
      "する\tは に\tロボットは ように\n",
      "する\tに が\t10月に 米DeepMind社が\n",
      "する\tが に\tAlphaGoが プロ囲碁棋士に\n",
      "呼ぶ\tと\tディープラーニングと\n",
      "する\tは が\t勝利して以降は 手法が\n",
      "与える\tが に\t人工知能が 雇用などに\n",
      "進める\tも が\t影響についても 研究が\n",
      "導き出す\tを\t関連性を\n",
      "導き出す\tを\tものを\n",
      "する\tを\t人工知能技術ディファレンシャブル・ニューラル・コンピューターを\n",
      "する\tが を\tデータが ワンショット学習を\n",
      "持つ\tを\t認識能力を\n",
      "する\tは を\t8月には 記号接地問題を\n",
      "なる\tと\t計算資源と\n",
      "付ける\tで に を\t画像処理コンテストで 手法に 圧倒的大差を\n",
      "する\tにより に が て\t高性能化により 2012年に ディープラーニングが 付けて\n",
      "集める\tに を\t急速に 注目を\n",
      "持つ\tを\t現実味を\n",
      "受け止める\tは て\t概念は 持って\n",
      "受ける\tを\t普及を\n",
      "する\tを\t汎用人工知能を\n",
      "立つ\tて は に が\t受けて 現場においては 筆頭に プロジェクトが\n",
      "する\tを\t脳を\n",
      "する\tて\tリバースエンジニアリングして\n",
      "組み合わせる\tを\t機械学習を\n",
      "する\tは と\t現場では 有望と\n",
      "扱う\tを\tタスクのみを\n",
      "進む\tから\tディープラーニングから\n",
      "扱う\tを\tタスクを\n",
      "する\tとして が\t結果として 理論が\n",
      "動かす\tで を\t仮想空間で モデルを\n",
      "学ぶ\tを に\tことを 高速に\n",
      "上げる\tも を\tことも 成果を\n",
      "考える\tと\t不可能と\n",
      "する\tを\t身体知を\n",
      "する\tと\t必要だと\n",
      "見せる\tを\t振る舞いを\n",
      "挑む\tに\t作成に\n",
      "ある\tて に\t考えて 関係に\n",
      "思う\tと\tあると\n",
      "する\tに\tデジタル的再現に\n",
      "いる\tも\t研究者も\n",
      "入る\tで が に\tコストで 計算リソースが 手に\n",
      "する\tが\tビッグデータが\n",
      "寄せる\tが に を\t企業が 活用に 関心を\n",
      "行う\tに で を\t全世界的に 民間企業主導で 投資を\n",
      "する\tて が\t行って 研究開発競争が\n",
      "する\tとして が に\t嚆矢として ITインフラが 急速に\n",
      "関わる\tも\t高速化にも\n",
      "できる\tを に\t組み合わせ最適化問題を リアルタイムに\n",
      "する\tが\t環境が\n",
      "受ける\tを\t動向を\n",
      "目立つ\tで から も が\t形で 2016年頃から ニュース番組でも 報道が\n",
      "する\tに\t急速に\n",
      "取る\tが に対して を\tイーロン・マスクが 人工知能に対して 人間が 遅れを\n",
      "する\tを に\t脳を 機械に\n",
      "する\tを\tブレイン・マシン・インターフェースを\n",
      "立つ\tに を\tために ニューラ・リンク社を\n",
      "する\tを\tことを\n",
      "なる\tは で に\t2017年には 世界中で 話題に\n",
      "する\tが\tインターネットが\n",
      "する\tにより が\tブレイン・マシン・インターフェースにより 事が\n",
      "含める\tまで\t位置関係まで\n",
      "できる\tは により て\t10月には ジェフリー・ヒントンにより 含めて\n",
      "する\tが\tカプセルネットワークが\n",
      "よる\tに\t提言に\n",
      "する\tを\tAIを\n",
      "できる\tで に\t事で 社会変革に\n",
      "する\tと\tよると 寄与できると\n",
      "する\tが を\tOpenAIが 好奇心を\n",
      "行う\tで を\t無報酬で 探索を\n",
      "いう\tと\t人間らしいと\n",
      "経る\tを\t段階を\n",
      "する\tを て\t推論を 経て\n",
      "分かる\tが に\t識別したのかが 明確に\n",
      "する\tは を\tMITリンカーン研究所は アーキテクチャを\n",
      "入る\tに\t2019年に\n",
      "する\tと まで\t入ると これまで 困難と\n",
      "ある\tにおいて が\t言語処理において 進展が\n",
      "する\tを\tWikipediaなどを\n",
      "上回る\tで を\t読解テストで 人間を\n",
      "至る\tに\t上回るに\n",
      "する\tと\tアレン脳科学研究所と\n",
      "生まれる\tによって\t脳スキャンによって\n",
      "する\tを\tデータを\n",
      "する\tは を\tGoogleは ソフトウェアを\n",
      "する\tが\tGoogleが\n",
      "達す\tで は に\t時点で データ量は 1Zettaバイトに\n",
      "いう\tと\t達していると\n",
      "始める\tとも を\tマックスプランク研究所とも 共同研究を\n",
      "する\tから を\t電子顕微鏡写真から 神経回路を\n",
      "行う\tは を\tGoogleは 研究を\n",
      "位置づける\tから を に\t第13次5カ年計画から AIを 国家プロジェクトに\n",
      "上げる\tも\t脳研究プロジェクトとしても\n",
      "する\tは で を\t中国では 官民一体で 研究開発を\n",
      "集める\tを\t天才児を\n",
      "投じる\tは て と に\t教育機関では 集めて 公然と 開発に\n",
      "よる\tに\t教授やなどに\n",
      "する\tと\t欧米と\n",
      "する\tを\t実験を\n",
      "ある\tは て に\t中国では 比較して 環境に\n",
      "する\tば と\tよれば あると\n",
      "する\tで を\t日本で 研究開発を\n",
      "する\tも において が\t齊藤元章も 開発において 中国が\n",
      "する\tを\t可能性を\n",
      "占める\tが\t中国が\n",
      "する\tは も\t4分の3は 占めてるとも\n",
      "よる\tに\t米国政府に\n",
      "超える\tを\t米国を\n",
      "なる\tば から は が て と\tよれば 2013年から 論文数では 中国が 超えて 世界一と\n",
      "する\tも が を\t大会でも 中国勢が 上位を\n",
      "ある\tでも\t幹部でも\n",
      "握る\tが で を\t中国が AIで 覇権を\n",
      "する\tと\t握りつつあると\n",
      "著す\tを\tするを\n",
      "取り上げる\tは て が\t台湾系アメリカ人科学者のは 著して メディアなどが\n",
      "向ける\tに\t開発支援に\n",
      "する\tで を\t5年で 15億ドルを\n",
      "する\tと\t支出すると\n",
      "開く\tを に\tAI研究所を パリに\n",
      "する\tは を\tフランス大統領エマニュエル・マクロンは 富士通などを\n",
      "する\tも\t連携も\n",
      "投じる\tが\t215億ユーロが\n",
      "する\tは に を\t韓国は 2022年までに 投資を\n",
      "する\tを\tAI機関を\n",
      "作る\tも\t褒賞制度も\n",
      "入る\tは に\t目標は 2022年までに 世界トップ4に\n",
      "いう\tと\t入ることだと\n",
      "よる\tに\t日経新聞調べに\n",
      "使う\tは が\tプログラミング言語は Pythonが\n",
      "する\tを\t深層学習を\n",
      "なる\tが と\t数学知識が 必要と\n",
      "行う\tを\t脳シミュレーションを\n",
      "なる\tは も\t行うには 知識も\n",
      "超える\tを\t人間を\n",
      "於く\tに\t超えるか内に\n",
      "起こす\tて に対して を\t於いて 人間に対して 反乱を\n",
      "する\tは を\t著書人工知能は 可能性を\n",
      "鳴らす\tを\t警鐘を\n",
      "いる\tは が について も\t松尾豊は 否定しているが 危険性について 著名人も\n",
      "併せ持つ\tを\t弾圧を\n",
      "する\tが で\t中華人民共和国が 開発競争で\n",
      "変わる\tは が\t教授は 既成概念が\n",
      "述べる\tと\t変わると\n",
      "呼ぶ\tと\t一人と\n",
      "する\tが で を\t中国が 政治目的で 人工知能を\n",
      "鳴らす\tは に を\t呼ばれているは ことに 警鐘を\n",
      "する\tに\t中国に\n",
      "する\tで を\t人工知能で 人権を\n",
      "呼ぶ\tは を と\tメディアなどは 政治体制を デジタル権威主義デジタル独裁デジタル警察国家デジタル全体主義AI独裁と\n",
      "埋め込む\tに\t帽子に\n",
      "する\tから を で\tセンサーから 感情を 人工知能で\n",
      "推し進める\tが\tプロジェクトが\n",
      "行う\tまで を に\t歩行者まで 監視を 人工知能に\n",
      "する\tに を\tロボットに 顔認識システムを\n",
      "行う\tは が\t中国では 監視社会・管理社会化が\n",
      "する\tから\t携帯電話などから\n",
      "する\tで\t人工知能で\n",
      "する\tを で\t個人情報を 人種プロファイリングで\n",
      "経る\tを\tウイグル族を 法的手続きを\n",
      "犯す\tに で も を\t経ずに 6月時点で 約1万5千人も 犯罪を\n",
      "ある\tが\t可能性が\n",
      "する\tは として に\t新疆ウイグル自治区では あるとして 新疆ウイグル再教育キャンプに\n",
      "する\tと\t予防拘禁していると\n",
      "報じる\tが\t内部文書であるが\n",
      "使う\tを\tAIを\n",
      "送る\tが を に\tコンピュータが 人間を 強制収容所に\n",
      "なる\tは として に\t人権侵害は ないとして 国際問題に\n",
      "恐れる\tを\t監視社会化を\n",
      "起きる\tが\t香港民主化デモが\n",
      "する\tを\t監視カメラを\n",
      "する\tは が に と\t香港では 際は スマート街灯が 市民に 次々と\n",
      "する\tは を に\t中国は AI監視技術を 世界各国に\n",
      "する\tを通じて が も\t国際電気通信連合を通じて 中国が 国際標準化も\n",
      "する\tが に\t人権侵害が 世界に\n",
      "する\tから が\tことから ことが 人権団体などから\n",
      "する\tに\t社会信用システムに\n",
      "する\tで を\t人工知能で ビッグデータを\n",
      "決める\tて を\t活用して 適性を\n",
      "する\tを\t格差を\n",
      "繋がる\tは に\t制度は ことに\n",
      "する\tと\t繋がると\n",
      "ある\tが\t懸念が\n",
      "認める\tを\t差別を\n",
      "する\tは から が\t欧州連合では 5月から EU一般データ保護規則が\n",
      "達す\tで は に\t9割超で IBMは 8割に\n",
      "ある\tに対して は で が\t達したのに対して Amazonは 6割で バイアスが\n",
      "する\tと\tあると\n",
      "する\tを\t研究を\n",
      "なる\tが で は と に\tマサチューセッツ工科大学が 精度で Megviiは 際は Amazonと 論争に\n",
      "試みる\tは を\t軍隊は 自動化を\n",
      "する\tを\t防空システムファランクスCIWSを\n",
      "できる\tは により を\tアメリカ海軍は ガトリング砲により 対艦ミサイルを\n",
      "する\tを\t対空迎撃ミサイルシステムアイアンドームを\n",
      "する\tを\t標的を\n",
      "する\tを\tサムソンRCWSを\n",
      "する\tは て を\tイスラエル軍は 境界線には 稼働させて 人間を\n",
      "生む\tは を\tAIは 軍事能力を\n",
      "変える\tを\t展開を\n",
      "する\tを\t戦争を\n",
      "決める\tを\t軍事バランスを\n",
      "なる\tは に\t変化は ことに\n",
      "ある\tも\t主張も\n",
      "する\tに\tP-1のように 戦闘指揮システムに 支援用に\n",
      "ある\tも\tことも\n",
      "する\tが\t研究チームが\n",
      "する\tは に\tALPHAは 一方的に\n",
      "する\tと\t勝利したと\n",
      "する\tは を\tAIプログラムは ファジィ制御を\n",
      "する\tは と\t処理能力は 必要と\n",
      "介す\tから を\t観点から 判断を\n",
      "出す\tを に\t開発禁止令を 2012年に\n",
      "する\tは を に\tアメリカ合衆国国防総省は 2017年には これを ものに\n",
      "勝ち残る\tに が\t人工知能に 人間が\n",
      "する\tとして が\t力として OODAループが\n",
      "する\tにより は\t軍事利用により 不安定化は\n",
      "する\tは と\t首脳らは 加速すると\n",
      "する\tに で\t2015年に ブエノスアイレスで\n",
      "出す\tで により が\t人工知能国際合同会議で 企業家らにより 公開書簡が\n",
      "操る\tを\t銃火器を\n",
      "続く\tに\t核兵器に\n",
      "とらえる\tと\t革命と\n",
      "なる\tは に\t一部は 数年以内に\n",
      "する\tに\t選別攻撃などに\n",
      "なる\tが にとって は\t開発競争が 人類にとって ものとは\n",
      "記す\tと\tならないと\n",
      "求める\tは が を\t4月には ヒューマン・ライツ・ウォッチが 禁止を\n",
      "行う\tは で が\t11月には 国際連合で 公式専門家会議が\n",
      "めぐる\tを\t運用を\n",
      "する\tを\t国際ルールを\n",
      "盛り込む\tに は も\t8月に 同会議は 採択するも 法的拘束力は\n",
      "ある\tに\t状態に\n",
      "評す\tも\tあるとも\n",
      "する\tに\t核開発に\n",
      "行う\tは を をめぐって\t米国・中国・ロシアは 開発競争を 軍事利用をめぐって\n",
      "する\tに で\t6月に 自律飛行実験で 飛行実験に\n",
      "する\tを\t記録を\n",
      "する\tを\t都市を\n",
      "する\tて は も\t更新して 5月には 映像も\n",
      "使う\tを\t自律無人艇を\n",
      "行う\tを\t試験を\n",
      "する\tは など で が に\t6月には 行うなど 技術で 中国が 急速に\n",
      "追い付く\tに\tアメリカに\n",
      "ある\tが\t可能性が\n",
      "する\tについて\tことについて\n",
      "備える\tに\t将来に\n",
      "ある\tは が\tアメリカ側では 必要が\n",
      "する\tは も\t中国は 主張も\n",
      "与える\tは に を\t軍用AI開発は 政界に 危機感を\n",
      "する\tで に\t設立などで 中国人民解放軍に\n",
      "する\tと を\t協力していると Googleを\n",
      "する\tと\tトランプ大統領と\n",
      "限る\tに\t中国に\n",
      "する\tは て に\tCEOサンダー・ピチャイは 面談して 成果は 人々に\n",
      "する\tと\t開放されていると\n",
      "なる\tは に\tドナルド・トランプ大統領は 事態に\n",
      "する\tが に\tGoogleが 軍事利用に\n",
      "行う\tを\t極秘計画メイヴン計画を\n",
      "する\tは が に\tアメリカでは ことが 社員に\n",
      "する\tに\t同様に\n",
      "する\tに\t中国政府に\n",
      "用いる\tを\t人工知能を\n",
      "する\tは\t人権侵害は\n",
      "誓う\tが\tGoogleが\n",
      "受ける\tは とともに と で を\t公聴会では 秘密計画とともに 拒否すると 整合性で 追及を\n",
      "関わる\tに が\t標的選択支援アルゴリズムに AI研究者が\n",
      "する\tと\t関わったと\n",
      "する\tは と\t際は モデリングと\n",
      "する\tが を\tMicrosoftが 共同研究を\n",
      "呼ぶ\tも に を\t際も 同様に 波紋を\n",
      "する\tが によって を\t中国が AIによって 監視国家を\n",
      "する\tで を に\t中東で 無人攻撃機を 大量に\n",
      "する\tて で に\t拡散させて AIで 自律的に\n",
      "する\tも\tドローン兵器も\n",
      "鳴らす\tに は を\t11月に マーク・エスパー国防長官は ことに 警鐘を\n",
      "する\tは\t中国は\n",
      "する\tと\t実用化してると\n",
      "する\tを\t個人を\n",
      "なりすます\tたり で\t攻撃したり ディープフェイクで\n",
      "操る\tたり により を\tなりすましたり ボット投稿により 世論を\n",
      "挙げる\tが\t懸念が\n",
      "する\tを で\t人工知能プロジェクトを 倫理面で\n",
      "する\tに で\tために 哲学者・政策立案者・経済学者・テクノロジスト等で\n",
      "する\tを\tAI倫理委員会を\n",
      "する\tは と\tGoogleは 設置すると\n",
      "する\tを\t反科学・反マイノリティ・地球温暖化懐疑論等を\n",
      "含む\tは も\t倫理委員会には 人物も\n",
      "する\tは を\tGoogle社員らは 解任を\n",
      "できる\tが に\t倫理委員会が 期待どおりに\n",
      "する\tが\tことが\n",
      "する\tは で を\tGoogleは 理由で 解散を\n",
      "する\tを に\t東洋哲学を AIに\n",
      "応じる\tに\tテーマに\n",
      "挙げる\tて は を\t応じて 井口尊仁は プロジェクトを\n",
      "見いだす\tに を\tものに 霊的存在を\n",
      "ある\tが\t文化が\n",
      "語る\tで と に\tアニミズムで ありますと 立石従寛に\n",
      "やる\tを\t悟りを\n",
      "やる\tて に\tやって AIに\n",
      "論じる\tを\tやらせるかを\n",
      "通じる\tは も\tアニミズム的人工知能論は 哲学塾東洋哲学篇にも\n",
      "する\tを と\tAIを 神と\n",
      "する\tは を\tアンソニー?レバンドウスキーは 宗教団体WayoftheFutureを\n",
      "基づく\tに\t人工知能に\n",
      "する\tを\t実現を\n",
      "する\tを通して を\t崇拝を通して 社会を\n",
      "する\tに\tことに\n",
      "する\tは と に\t使命は ことと 抽象的に\n",
      "関連付ける\tと\t歴史などと\n",
      "する\tは て\t海外メディアは 関連付けて\n",
      "する\tが を\tレバンドウスキーが 機密情報を\n",
      "訴える\tを\tことを\n",
      "行う\tを\t裁判を\n",
      "する\tは を\t我々は 世界を\n",
      "する\tに対し ずつ と\t元CEOに対し ひとつずつ 征服するんだと\n",
      "示す\tは を\tWaymoは レバンドウスキーは 振る舞いを\n",
      "なる\tは も\t釈徹宗は 線引きも\n",
      "述べる\tと\tと\n",
      "よる\tに\t内田樹に\n",
      "する\tば は を\tよれば 哲学者は 話を\n",
      "いう\tと\tと\n",
      "言う\tが\t発明家レイ・カーツワイルが\n",
      "する\tが\t哲学者ジョン・サールが\n",
      "よる\tに\tダニエル・デネットに\n",
      "できる\tが によって\t意識が 形式論理システムによって\n",
      "する\tと は\tよると 思考実験は 実現できないと\n",
      "語る\tを\t科学を\n",
      "する\tが は と\t哲学的考察が 実際には 科学と\n",
      "する\tにおいて は を\tことかにおいて 須藤靖は ことを\n",
      "する\tを\t問題を\n",
      "する\tに\t脳科学・計算機科学・人工知能研究開発等に\n",
      "残す\tて は も を\t関連して フランシス・クリックは 何も 成果を\n",
      "する\tと\t残してこなかったと\n",
      "過ぎる\tにおいて は に\t観点において 哲学は 学問・科学に\n",
      "する\tと\t過ぎないと\n",
      "する\tに\tクリックに\n",
      "まじる\tの\t私の\n",
      "なる\tは に\tこれは 愚痴に\n",
      "思う\tと\t暇だと\n",
      "述べる\tは と\t澤口俊之は 思うと\n",
      "始まる\tは から\t哲学は 暇から\n",
      "伝える\tと が\t始まったと アリストテレスが\n",
      "言う\tと は\t的外れではないと 野家啓一は\n",
      "違う\tは\t科学とは\n",
      "語る\tは で を\t哲学者は 日常的言語で 宇宙を\n",
      "する\tは を\t理論物理学者ディラックは 哲学者を\n",
      "見る\tが\tディラックが\n",
      "含める\tを\tウィトゲンシュタインを\n",
      "する\tどころか さえ\t量子力学どころか 概念さえ\n",
      "使う\tを\t日常的言語を\n",
      "行う\tを\t意思疎通を\n",
      "できる\tも は\t使っても ことは\n",
      "する\tと\t考えだと\n",
      "よる\tに\t創られるに\n",
      "伴う\tに\t発展に\n",
      "論じる\tて が で\t伴って 哲学が 一部で\n",
      "言う\tと\t特異点と\n",
      "する\tと\tシンギュラリティと\n",
      "超える\tを\t脳を\n",
      "できる\tが\t言明自体が\n",
      "記す\tは と\t前掲書は 定義できていないと\n",
      "捉える\tを として\t脳を デジタル情報処理システムとして\n",
      "見る\tから\t観点から\n",
      "起こる\tに ば は\t確かに 見れば シンギュラリティは\n",
      "する\tが\tアナログが\n",
      "示す\tは が で\t脳は ことが 観察結果で\n",
      "よる\tに\t前掲書に\n",
      "する\tは が\t神経膜では ノイズが\n",
      "生み出す\tによって が\tアナログ量によって カオスが\n",
      "する\tを で\t状況を デジタルで\n",
      "考える\tと\tよると 困難と\n",
      "述べる\tは と\t哲学者は 専門家ではないと\n",
      "基づく\tが に\t多くが 自由連想に\n",
      "する\tは と\t田中一之は トルケル?フランセーンは 基づいていると\n",
      "よる\tに\t田中に\n",
      "書く\tについて が\t不完全性定理について 哲学者が\n",
      "する\tが に\t本が 頃に\n",
      "する\tと が は によって\tよると 書店販売されていたが 本は 専門誌によって\n",
      "する\tを\t勘違いを\n",
      "する\tが について\t高かったが 核について\n",
      "見る\tは も\t間違いは 入門書などにも\n",
      "よる\tに\tフランセーンに\n",
      "起こる\tは に\t誤解・誤用は 一般に\n",
      "する\tば も\tよれば 神学でも\n",
      "示す\tに が\t1931年に ゲーデルが\n",
      "語る\tを\t科学を\n",
      "よる\tに\tことかに\n",
      "扱う\tの\t学問の\n",
      "する\tが\t問題が\n",
      "異なる\tも\t哲学も\n",
      "する\tと を\tよると 問題を\n",
      "言う\tは と\tこれは 進歩だと 須藤は\n",
      "含む\tを\t要素を\n",
      "扱う\tを に\t問題を 哲学的・統一的に\n",
      "する\tで は について\t一方で 伊勢田哲治は 天文学について\n",
      "扱う\tは を\t天文学では 〔哲学的〕問題を\n",
      "扱う\tも を\t物理学でも 問題を\n",
      "述べる\tと\t扱わないと\n",
      "ある\tに か が\tそれ自体に 何か 問題が\n",
      "返す\tが と\tその通りですが あるのでしょうかと\n",
      "述べる\tは も\t須藤は 次のようにも\n",
      "論じる\tに\t哲学的に\n",
      "取り上げる\tを\t言葉を\n",
      "する\tて を に\t取り上げて 言葉を 具体的に\n",
      "述べる\tと\t不可能ですと\n",
      "持つ\tが を\t哲学者が 興味を\n",
      "違う\tが は\t定義が 物理学者とは\n",
      "する\tは\t須藤は ことは\n",
      "しれる\tは\t違いというのは\n",
      "述べる\tは と\t伊勢田は 大きいのかもしれませんと\n",
      "行う\tで は まで を\t対談で 須藤は これまで 議論を\n",
      "なる\tで は\tおかげで 違いは\n",
      "思う\tは\t明らかになったとは\n",
      "つく\tか が\t何か 決着が\n",
      "する\tと\tつくのでしょうか？と\n",
      "つく\tは\t伊勢田は 決着は\n",
      "答える\tが と\t思いますが つかないでしょうねと\n"
     ]
    }
   ],
   "source": [
    "for _chunks in sentences:\n",
    "    _text = ''\n",
    "    for _chunk in _chunks:\n",
    "        for _morph in _chunk.morphs:\n",
    "            _text = _text + _morph.surface\n",
    "            if _morph.pos == '動詞':\n",
    "                _particles = []\n",
    "                _surfaces = []\n",
    "                for _src in _chunk.srcs:\n",
    "                    _surface = ''\n",
    "                    if _chunks[_src].morphs[-1].pos == '助詞':\n",
    "                        if _chunks[_src].morphs[-1].base not in _particles:\n",
    "                            _particles.append(_chunks[_src].morphs[-1].base)\n",
    "                        for _src_morph in _chunks[_src].morphs:\n",
    "                            _surface = _surface + _src_morph.surface\n",
    "                        _surfaces.append(_surface)\n",
    "                            \n",
    "                if len(_particles) > 0:\n",
    "                    _particle_list = ' '.join(_particles)\n",
    "                    _surface_list = ' '.join(_surfaces)\n",
    "                    print(f'{_morph.base}\\t{_particle_list}\\t{_surface_list}')\n",
    "\n",
    "                break\n",
    "\n",
    "    # print(_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c6632",
   "metadata": {},
   "source": [
    "47. 機能動詞構文のマイニング\n",
    "\n",
    "* 動詞のヲ格にサ変接続名詞が入っている場合のみに着目したい．46のプログラムを以下の仕様を満たすように改変せよ．\n",
    "  * 「サ変接続名詞+を（助詞）」で構成される文節が動詞に係る場合のみを対象とする\n",
    "  * 述語は「サ変接続名詞+を+動詞の基本形」とし，文節中に複数の動詞があるときは，最左の動詞を用いる\n",
    "  * 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "  * 述語に係る文節が複数ある場合は，すべての項をスペース区切りで並べる（助詞の並び順と揃えよ）\n",
    "\n",
    "例えば「また、自らの経験を元に学習を行う強化学習という手法もある。」という文から，以下の出力が得られるはずである．\n",
    "```\n",
    "学習を行う\tに を\t元に 経験を\n",
    "\n",
    "＃＃＃ cabocha の出力 ＃＃＃\n",
    "* 0 8D 0/0 -1.930928\n",
    "また\t接続詞,*,*,*,*,*,また,マタ,マタ\n",
    "、\t記号,読点,*,*,*,*,、,、,、\n",
    "* 1 2D 0/1 1.962863\n",
    "自ら\t名詞,副詞可能,*,*,*,*,自ら,ミズカラ,ミズカラ\n",
    "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
    "* 2 5D 0/1 0.574114\n",
    "経験\t名詞,サ変接続,*,*,*,*,経験,ケイケン,ケイケン\n",
    "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
    "* 3 5D 0/1 1.647927\n",
    "元\t名詞,一般,*,*,*,*,元,モト,モト\n",
    "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
    "* 4 5D 0/1 2.489314\n",
    "学習\t名詞,サ変接続,*,*,*,*,学習,ガクシュウ,ガクシュー\n",
    "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
    "* 5 6D 0/0 1.354331\n",
    "行う\t動詞,自立,*,*,五段・ワ行促音便,基本形,行う,オコナウ,オコナウ\n",
    "* 6 7D 1/2 1.920681\n",
    "強化\t名詞,サ変接続,*,*,*,*,強化,キョウカ,キョーカ\n",
    "学習\t名詞,サ変接続,*,*,*,*,学習,ガクシュウ,ガクシュー\n",
    "という\t助詞,格助詞,連語,*,*,*,という,トイウ,トユウ\n",
    "* 7 8D 0/1 -1.930928\n",
    "手法\t名詞,一般,*,*,*,*,手法,シュホウ,シュホー\n",
    "も\t助詞,係助詞,*,*,*,*,も,モ,モ\n",
    "* 8 -1D 0/0 0.000000\n",
    "ある\t動詞,自立,*,*,五段・ラ行,基本形,ある,アル,アル\n",
    "。\t記号,句点,*,*,*,*,。,。,。\n",
    "EOS\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12f033e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "注目を集める\tが\tサポートベクターマシンが\n",
      "学習を行う\tを に\t経験を 元に\n",
      "進化を見せる\tは て において\tGANは 加えて 生成技術において\n",
      "開発を行う\tは\tエイダ・ラブレスは\n",
      "処理を行う\tにより に\tティム・バーナーズ＝リーにより Webに\n",
      "処理を行う\tに て に\tデータに 付加して コンピュータに\n",
      "研究を進める\tて\t費やして\n",
      "運転をする\tに\t元に\n",
      "特許をする\tに が\t2018年までに 日本が\n",
      "運転をする\tて に\t基づいて 柔軟に\n",
      "注目を集める\tから は\tことから ファジィは\n",
      "制御を用いる\tて も\t受けて 他社も\n",
      "改善を果たす\tに で が\t2012年に 画像処理コンテストで チームが\n",
      "研究を続ける\tが て\tジェフ・ホーキンスが 向けて\n",
      "学習をする\tが\tデータが\n",
      "注目を集める\tに\t急速に\n",
      "投資を行う\tに で\t全世界的に 民間企業主導で\n",
      "探索を行う\tで\t無報酬で\n",
      "研究を行う\tとも は\tマックスプランク研究所とも Googleは\n",
      "開発をする\tは で\t中国では 官民一体で\n",
      "開発をする\tで\t日本で\n",
      "投資をする\tは に\t韓国は 2022年までに\n",
      "反乱を起こす\tて に対して\t於いて 人間に対して\n",
      "手続きを経る\tを\tウイグル族を\n",
      "制御をする\tは\tAIプログラムは\n",
      "判断を介す\tから\t観点から\n",
      "禁止を求める\tは が\t4月には ヒューマン・ライツ・ウォッチが\n",
      "追及を受ける\tは とともに と で\t公聴会では 秘密計画とともに 拒否すると 整合性で\n",
      "研究をする\tが\tMicrosoftが\n",
      "解任をする\tは\tGoogle社員らは\n",
      "解散をする\tは で\tGoogleは 理由で\n",
      "存在を見いだす\tに\tものに\n",
      "話をする\tば は\tよれば 哲学者は\n",
      "議論を行う\tで は まで\t対談で 須藤は これまで\n"
     ]
    }
   ],
   "source": [
    "for _chunks in sentences:\n",
    "    _text = ''\n",
    "    _flag = False\n",
    "    _verb = ''\n",
    "    _particles = []\n",
    "    _surfaces = []\n",
    "    for i in range(len(_chunks)):\n",
    "        _text = _text + ' '\n",
    "        for j in range(len(_chunks[i].morphs)):\n",
    "            _text = _text + '/' + _chunks[i].morphs[j].surface\n",
    "            if _chunks[i].morphs[j].pos == '名詞' and _chunks[i].morphs[j].pos1 == 'サ変接続':\n",
    "                if j+1 < len(_chunks[i].morphs) and _chunks[i].morphs[j+1].pos == '助詞' and _chunks[i].morphs[j+1].surface == 'を':\n",
    "                    if i+1 < len(_chunks):\n",
    "                        for k in range(len(_chunks[i+1].morphs)):\n",
    "                            if _chunks[i+1].morphs[k].pos == '動詞':\n",
    "                                _verb = _chunks[i].morphs[j].surface + _chunks[i].morphs[j+1].surface + _chunks[i+1].morphs[k].base\n",
    "                                for _src in _chunks[i+1].srcs:\n",
    "                                    if _chunks[_src].morphs[-1].pos == '助詞' and _src != _chunks[i].i:\n",
    "                                        _flag = True\n",
    "                                        _particles.append(_chunks[_src].morphs[-1].surface)\n",
    "                                        _surface = ''\n",
    "                                        for _src_morph in _chunks[_src].morphs:\n",
    "                                            _surface = _surface + _src_morph.surface\n",
    "                                        _surfaces.append(_surface)\n",
    "                                break\n",
    "\n",
    "    if _flag:\n",
    "        print(f'{_verb}\\t{\" \".join(_particles)}\\t{\" \".join(_surfaces)}')\n",
    "        # print(_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95a47f",
   "metadata": {},
   "source": [
    "48. 名詞から根へのパスの抽出\n",
    "\n",
    "* 文中のすべての名詞を含む文節に対し，その文節から構文木の根に至るパスを抽出せよ． ただし，構文木上のパスは以下の仕様を満たすものとする．\n",
    "  * 各文節は（表層形の）形態素列で表現する\n",
    "  * パスの開始文節から終了文節に至るまで，各文節の表現を” -> “で連結する\n",
    "\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」\n",
    "```\n",
    "ジョンマッカーシーは -> 作り出した\n",
    "AIに関する -> 最初の -> 会議で -> 作り出した\n",
    "最初の -> 会議で -> 作り出した\n",
    "会議で -> 作り出した\n",
    "人工知能という -> 用語を -> 作り出した\n",
    "用語を -> 作り出した\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f128ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工知能\n",
      "人工知能とは -> 語\n",
      "計算という -> 概念と -> コンピュータという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す -> 語\n",
      "概念と -> コンピュータという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す -> 語\n",
      "コンピュータという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す -> 語\n",
      "道具を -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す -> 語\n",
      "知能を -> 研究する -> 計算機科学の -> 一分野を -> 指す -> 語\n",
      "研究する -> 計算機科学の -> 一分野を -> 指す -> 語\n",
      "計算機科学の -> 一分野を -> 指す -> 語\n",
      "一分野を -> 指す -> 語\n",
      "語\n",
      "言語の -> 推論 -> 問題解決などの -> 知的行動を -> 代わって -> 行わせる -> 技術または -> 研究分野とも -> される\n",
      "理解や -> 推論 -> 問題解決などの -> 知的行動を -> 代わって -> 行わせる -> 技術または -> 研究分野とも -> される\n",
      "推論 -> 問題解決などの -> 知的行動を -> 代わって -> 行わせる -> 技術または -> 研究分野とも -> される\n",
      "問題解決などの -> 知的行動を -> 代わって -> 行わせる -> 技術または -> 研究分野とも -> される\n",
      "知的行動を -> 代わって -> 行わせる -> 技術または -> 研究分野とも -> される\n",
      "人間に -> 代わって -> 行わせる -> 技術または -> 研究分野とも -> される\n",
      "コンピューターに -> 行わせる -> 技術または -> 研究分野とも -> される\n",
      "技術または -> 研究分野とも -> される\n",
      "計算機による -> 情報処理システムの -> 実現に関する -> 研究分野とも -> される\n",
      "知的な -> 情報処理システムの -> 実現に関する -> 研究分野とも -> される\n",
      "情報処理システムの -> 実現に関する -> 研究分野とも -> される\n",
      "設計や -> 実現に関する -> 研究分野とも -> される\n",
      "実現に関する -> 研究分野とも -> される\n",
      "研究分野とも -> される\n",
      "日本大百科全書の -> 解説で -> 述べている\n",
      "解説で -> 述べている\n",
      "情報工学者・通信工学者の -> 佐藤理史は -> 述べている\n",
      "佐藤理史は -> 述べている\n",
      "次のように -> 述べている\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for _chunks in sentences:\n",
    "    for _chunk in _chunks:\n",
    "        _i = -1\n",
    "        for _morph in _chunk.morphs:\n",
    "            if _morph.pos == '名詞':\n",
    "                _i = _chunk.i\n",
    "                break\n",
    "        if _i != -1:\n",
    "            _tree = []\n",
    "            while _i != -1:\n",
    "                _phrase = ''\n",
    "                for _morph in _chunks[_i].morphs:\n",
    "                    _phrase = _phrase + _morph.surface\n",
    "                _tree.append(_phrase)\n",
    "                _i = _chunks[_i].dst\n",
    "            print(' -> '.join(_tree))\n",
    "            # break\n",
    "    i = i + 1\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31ea1e1",
   "metadata": {},
   "source": [
    "49. 名詞間の係り受けパスの抽出\n",
    "\n",
    "* 文中のすべての名詞句のペアを結ぶ最短係り受けパスを抽出せよ．ただし，名詞句ペアの文節番号がiとj（i<j）のとき，係り受けパスは以下の仕様を満たすものとする．\n",
    "  * 問題48と同様に，パスは開始文節から終了文節に至るまでの各文節の表現（表層形の形態素列）を” -> “で連結して表現する\n",
    "  * 文節iとjに含まれる名詞句はそれぞれ，XとYに置換する\n",
    "* また，係り受けパスの形状は，以下の2通りが考えられる．\n",
    "  * 文節iから構文木の根に至る経路上に文節jが存在する場合: 文節iから文節jのパスを表示\n",
    "  * 上記以外で，文節iと文節jから構文木の根に至る経路上で共通の文節kで交わる場合: 文節iから文節kに至る直前のパスと文節jから文節kに至る直前までのパス，文節kの内容を” | “で連結して表示\n",
    "\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」\n",
    "```\n",
    "Xは | Yに関する -> 最初の -> 会議で | 作り出した\n",
    "Xは | Yの -> 会議で | 作り出した\n",
    "Xは | Yで | 作り出した\n",
    "Xは | Yという -> 用語を | 作り出した\n",
    "Xは | Yを | 作り出した\n",
    "Xに関する -> Yの\n",
    "Xに関する -> 最初の -> Yで\n",
    "Xに関する -> 最初の -> 会議で | Yという -> 用語を | 作り出した\n",
    "Xに関する -> 最初の -> 会議で | Yを | 作り出した\n",
    "Xの -> Yで\n",
    "Xの -> 会議で | Yという -> 用語を | 作り出した\n",
    "Xの -> 会議で | Yを | 作り出した\n",
    "Xで | Yという -> 用語を | 作り出した\n",
    "Xで | Yを | 作り出した\n",
    "Xという -> Yを\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4084a7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXとは -> X\n",
      "Xという -> Xと\n",
      "Xという -> 概念と -> Xという\n",
      "Xという -> 概念と -> コンピュータという -> Xを\n",
      "Xという -> 概念と -> コンピュータという -> 道具を -> 用いて -> Xする\n",
      "Xという -> 概念と -> コンピュータという -> 道具を -> 用いて -> 研究する -> XXXの\n",
      "Xという -> 概念と -> コンピュータという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> XXを\n",
      "Xという -> 概念と -> コンピュータという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す -> X\n",
      "Xと -> Xという\n",
      "Xと -> コンピュータという -> Xを\n",
      "Xと -> コンピュータという -> 道具を -> 用いて -> Xする\n",
      "Xと -> コンピュータという -> 道具を -> 用いて -> 研究する -> XXXの\n",
      "Xと -> コンピュータという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> XXを\n",
      "Xと -> コンピュータという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す -> X\n",
      "Xという -> Xを\n",
      "Xという -> 道具を -> 用いて -> Xする\n",
      "Xという -> 道具を -> 用いて -> 研究する -> XXXの\n",
      "Xという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> XXを\n",
      "Xという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す -> X\n",
      "Xを -> 用いて -> Xする\n",
      "Xを -> 用いて -> 研究する -> XXXの\n",
      "Xを -> 用いて -> 研究する -> 計算機科学の -> XXを\n",
      "Xを -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す -> X\n",
      "Xを -> Xする\n",
      "Xを -> 研究する -> XXXの\n",
      "Xを -> 研究する -> 計算機科学の -> XXを\n",
      "Xを -> 研究する -> 計算機科学の -> 一分野を -> 指す -> X\n",
      "Xする -> XXXの\n",
      "Xする -> 計算機科学の -> XXを\n",
      "Xする -> 計算機科学の -> 一分野を -> 指す -> X\n",
      "Xを -> 用いて | Xを | Xする\n",
      "Xという -> 道具を -> 用いて | Xを | Xする\n",
      "Xと -> コンピュータという -> 道具を -> 用いて | Xを | Xする\n",
      "Xという -> 概念と -> コンピュータという -> 道具を -> 用いて | Xを | Xする\n",
      "XXXの -> XXを\n",
      "XXXの -> 一分野を -> 指す -> X\n",
      "XXを -> 指す -> X\n",
      "XXとは | XXを -> 指す | X\n",
      "XXとは | XXXの -> 一分野を -> 指す | X\n",
      "XXとは | Xする -> 計算機科学の -> 一分野を -> 指す | X\n",
      "XXとは | Xを -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す | X\n",
      "XXとは | Xという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す | X\n",
      "XXとは | Xと -> コンピュータという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す | X\n",
      "XXとは | Xという -> 概念と -> コンピュータという -> 道具を -> 用いて -> 研究する -> 計算機科学の -> 一分野を -> 指す | X\n",
      "XXとは | Xを -> 研究する -> 計算機科学の -> 一分野を -> 指す | X\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def get_chunk_attributes(_chunk):\n",
    "    _i = -1\n",
    "    _dst = -1\n",
    "    _srcs = []\n",
    "    _phrase = ''\n",
    "    _masked_phrase = ''\n",
    "    _flag = False\n",
    "    for j in range(len(_chunk.morphs)):\n",
    "        _i = _chunk.i\n",
    "        _dst = _chunk.dst\n",
    "        _srcs = _chunk.srcs\n",
    "        if _chunk.morphs[j].pos == '名詞':\n",
    "            _flag = True\n",
    "            _masked_phrase = _masked_phrase + 'X'\n",
    "        else:\n",
    "            _masked_phrase = _masked_phrase + _chunk.morphs[j].surface\n",
    "        _phrase = _phrase + _chunk.morphs[j].surface\n",
    "    return {'i': _i, 'dst': _dst, 'srcs': _srcs, 'phrase': _phrase, 'masked_phrase': _masked_phrase, 'flag': _flag}\n",
    "\n",
    "\n",
    "def traverse(branch_1_i, branch_1_list, branch_2_i, branch_2_list, root_i, chunks):\n",
    "    # print('####', branch_1_i, branch_2_i, root_i)\n",
    "    branch_1_attributes = get_chunk_attributes(chunks[branch_1_i])\n",
    "    branch_2_attributes = get_chunk_attributes(chunks[branch_2_i])\n",
    "    root_attributes = get_chunk_attributes(chunks[root_i])\n",
    "    if root_attributes['flag']:\n",
    "        root_output = root_attributes[\"masked_phrase\"]\n",
    "    else:\n",
    "        root_output = root_attributes[\"phrase\"]\n",
    "\n",
    "    if branch_1_attributes['flag'] and branch_2_attributes['flag']:\n",
    "        # print(branch_1_attributes['i'], \n",
    "        #         branch_1_attributes['masked_phrase'], branch_1_attributes['phrase'], branch_1_list, ' | ',\n",
    "        #         branch_2_attributes['i'], \n",
    "        #         branch_2_attributes['masked_phrase'], branch_2_attributes['phrase'], branch_2_list, ' | ',\n",
    "        #         f'({root_attributes[\"i\"]}, {root_attributes[\"masked_phrase\"]}, {root_attributes[\"phrase\"]})')\n",
    "        \n",
    "        if len(branch_1_list) > 0:\n",
    "            branch_1_output = branch_1_attributes['masked_phrase'] + ' -> ' + ' -> '.join(branch_1_list)\n",
    "        else:\n",
    "            branch_1_output = branch_1_attributes['masked_phrase']\n",
    "\n",
    "        if len(branch_2_list) > 0:\n",
    "            branch_2_output = branch_2_attributes['masked_phrase'] + ' -> ' + ' -> '.join(branch_2_list)\n",
    "        else:\n",
    "            branch_2_output = branch_2_attributes['masked_phrase']\n",
    "\n",
    "        print(branch_1_output, '|', branch_2_output, '|', root_output)\n",
    "\n",
    "    if len(branch_1_attributes['srcs']) > 0:\n",
    "        branch_1_list_copy = copy.copy(branch_1_list)\n",
    "        branch_1_list_copy.insert(0, branch_1_attributes['phrase'])\n",
    "        for branch_1_next in branch_1_attributes['srcs']:\n",
    "            traverse(branch_1_next, branch_1_list_copy, branch_2_i, branch_2_list, root_i, chunks)\n",
    "\n",
    "    if len(branch_2_attributes['srcs']) > 0:\n",
    "        branch_2_list_copy = copy.copy(branch_2_list)\n",
    "        branch_2_list_copy.insert(0, branch_2_attributes['phrase'])\n",
    "        for branch_2_next in branch_2_attributes['srcs']:\n",
    "            traverse(branch_1_i, branch_1_list, branch_2_next, branch_2_list_copy, root_i, chunks)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for _chunks in sentences:\n",
    "    for i in range(len(_chunks)):\n",
    "        i_attributes = get_chunk_attributes(_chunks[i])\n",
    "        if i_attributes['flag'] and i_attributes['dst'] != -1:\n",
    "            _tree = []\n",
    "            dst_attributes = get_chunk_attributes(_chunks[i_attributes['dst']])\n",
    "            while True:\n",
    "                if dst_attributes['flag']:\n",
    "                    # print('#', i_attributes['i'], f'({i_attributes[\"phrase\"]},{i_attributes[\"masked_phrase\"]})', \n",
    "                    #     _tree, dst_attributes['srcs'], f'({dst_attributes[\"phrase\"]},{dst_attributes[\"masked_phrase\"]})')\n",
    "                    if len(_tree) > 0:\n",
    "                        print(f'{i_attributes[\"masked_phrase\"]} ->', \n",
    "                            ' -> '.join(_tree), f'-> {dst_attributes[\"masked_phrase\"]}')\n",
    "                    else:\n",
    "                        print(f'{i_attributes[\"masked_phrase\"]} -> {dst_attributes[\"masked_phrase\"]}')\n",
    "\n",
    "                _tree.append(dst_attributes['phrase'])\n",
    "                if dst_attributes['dst'] == -1:\n",
    "                    break\n",
    "                else:\n",
    "                    dst_attributes = get_chunk_attributes(_chunks[dst_attributes['dst']])\n",
    "\n",
    "        if len(i_attributes['srcs']) > 1:\n",
    "            # print('##', i_attributes['srcs'], f'({i_attributes[\"i\"]}, {i_attributes[\"masked_phrase\"]}, {i_attributes[\"phrase\"]})')\n",
    "            for j in range(len(i_attributes['srcs'])-1):\n",
    "                _branch_1 = []\n",
    "                for k in range(j+1, len(i_attributes['srcs'])):\n",
    "                    _branch_2 = []\n",
    "                    traverse(i_attributes['srcs'][j], _branch_1, i_attributes['srcs'][k], _branch_2, i_attributes[\"i\"], _chunks)\n",
    "\n",
    "    i = i + 1\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ef2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
